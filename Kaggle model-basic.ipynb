{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import argparse\n",
    "import codecs\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Combined_News_DJIA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 27)\n",
      "(378, 27)\n"
     ]
    }
   ],
   "source": [
    "train = data.iloc[0:1611]\n",
    "test = data[1611:]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 25)\n",
      "[0 1 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "trainheadlines = data.iloc[0:1611, 2:27].values\n",
    "trainLabels = data.iloc[0:1611, 1].values\n",
    "testheadlines = data.iloc[1611:, 2:27].values\n",
    "testLabels = data.iloc[1611:, 1].values\n",
    "\n",
    "print(trainheadlines.shape)\n",
    "print(trainLabels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 31675)\n"
     ]
    }
   ],
   "source": [
    "trainVocab = []\n",
    "for row in range(0,len(train.index)):\n",
    "    trainVocab.append(' '.join(str(x) for x in train.iloc[row,2:27]))\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "basictrain = vectorizer.fit_transform(trainVocab)\n",
    "print(basictrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 14073)\n"
     ]
    }
   ],
   "source": [
    "trainheadlines = []\n",
    "trainLabels = []\n",
    "for row in range(0,len(train.index)):\n",
    "    trainheadlines.append(' '.join(str(x) for x in train.iloc[row,2:27]))\n",
    "    trainLabels.append(int(train.iloc[row,1]))\n",
    "\n",
    "basicvectorizer = CountVectorizer(min_df=3)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "print(basictrain.shape)\n",
    "\n",
    "testheadlines = []\n",
    "testLabels = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "    testLabels.append(test.iloc[row,1])\n",
    "\n",
    "basictest = basicvectorizer.transform(testheadlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformHeadlines(headlines):\n",
    "    outputHeadlines = np.empty([headlines.shape[0], 5])\n",
    "    for i, headline in enumerate(headlines):\n",
    "        outputHeadline = [vectorizer.vocabulary_[x] if x in vectorizer.vocabulary_ else -1 for x in vectorizer.build_tokenizer()(headline.lower())]\n",
    "        outputHeadlines[i] = outputHeadline[:5]\n",
    "        \n",
    "    return np.asarray(outputHeadlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import tensorflow as tf\n",
    "\n",
    "class LSTMLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LSTMLayer, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.lstmLayers = []\n",
    "        for i in range(25):\n",
    "            self.lstmLayers.append(nn.LSTM(input_dim, output_dim))\n",
    "        self.basicLSTM = nn.LSTM(input_dim, output_dim)\n",
    "        self.fc = nn.Linear(output_dim, 2)\n",
    "\n",
    "    def forward(self, headlines, hidden = None, cell = None):\n",
    "        outputs = []\n",
    "        new_hiddens = []\n",
    "        if hidden is None:\n",
    "            hidden = Variable(torch.zeros(1, 1, self.output_dim)).float()\n",
    "            cell = Variable(torch.zeros(1, 1, self.output_dim)).float()\n",
    "        hidden = hidden.cuda()\n",
    "        cell = cell.cuda()\n",
    "        headlinesTransformed = Variable(torch.from_numpy(np.asarray(headlines.todense().astype(float)))).view(1,1,-1).float().cuda();\n",
    "        output, (hidden, cell) = self.basicLSTM(headlinesTransformed,\n",
    "                                                (hidden, cell))\n",
    "        log_probs = F.log_softmax(self.fc(output[0]), dim=-1)\n",
    "        return log_probs, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basicvectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8362a8d75228>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasicvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasictrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'basicvectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "print(basicvectorizer.inverse_transform(basictrain[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 16:38:07.258206 :: Epoch 199 :: Iter 1611 / 1611 :: train loss: 138.5437\r"
     ]
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "lstmLayer = LSTMLayer(basictrain[0].shape[1], 100).cuda()\n",
    "# predictLayer = PredictLayer(30).cuda()\n",
    "\n",
    "learning_rate = 0.1\n",
    "lstmOptimizer = torch.optim.Adam(lstmLayer.parameters(), lr=learning_rate)\n",
    "#predictOptimizer = torch.optim.Adam(predictLayer.parameters(), lr=learning_rate)\n",
    "epoch = 0\n",
    "train_log_string = '%s :: Epoch %i :: Iter %i / %i :: train loss: %0.4f'\n",
    "train_loss = []\n",
    "criterion = torch.nn.NLLLoss()\n",
    "trainLabelVar = Variable(torch.LongTensor(trainLabels)).cuda()\n",
    "\n",
    "while epoch < 200:\n",
    "    cell = None\n",
    "    hidden = None\n",
    "    total_loss = 0\n",
    "    for (i, headlines) in enumerate(basictrain):\n",
    "#         if i == 500:\n",
    "#             break\n",
    "        lstmOptimizer.zero_grad()\n",
    "        log_probs, hidden, cell = lstmLayer(headlines, hidden, cell)\n",
    "        loss = criterion(log_probs, trainLabelVar[i])\n",
    "        total_loss += loss\n",
    "    total_loss.backward()\n",
    "        \n",
    "    lstmOptimizer.step()\n",
    "    train_loss.append(total_loss.data)\n",
    "    if ((i) % 10) == 0:\n",
    "        print(train_log_string % (datetime.now(), epoch, i+1, len(trainheadlines), np.mean(train_loss)), end='\\r')\n",
    "#         print('')\n",
    "    epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  1135.1416\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  5414.7842\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1375.4298\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1191.9204\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1134.5706\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1126.3152\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1113.2526\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1077.9924\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1043.4398\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1085.4072\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1048.7307\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  1016.1223\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  956.4117\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  943.6127\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  911.4258\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  897.6584\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  899.7159\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  910.7770\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  778.8517\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  789.2477\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  810.0379\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  748.4029\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  706.2678\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  731.9000\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  754.3074\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  741.5229\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  714.3303\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  728.7491\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  743.4699\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  690.1865\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  659.9462\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  652.3475\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  666.8655\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  705.4634\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  670.3304\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  640.3311\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  623.6587\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  625.9861\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  623.3235\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  600.0842\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  596.0487\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  599.8169\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  592.0491\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  583.6690\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  585.4668\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  581.7828\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  574.7723\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  566.8934\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  568.4548\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  563.5839\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  562.7523\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  558.1271\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  558.9518\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  557.8223\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  557.3949\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  558.4087\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  556.8930\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  553.7703\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  582.8510\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  624.4981\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  578.9824\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  558.9781\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  643.9300\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  550.7772\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  548.3857\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  634.6281\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  654.8113\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  633.7905\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  635.1601\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  557.7420\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  545.5936\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  565.7460\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  595.3320\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  594.3722\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  511.0022\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  498.2297\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  494.8795\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  495.6481\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  491.5004\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  481.6077\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  479.9628\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  473.3263\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  478.0583\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  469.3502\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  467.1787\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  470.3908\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  467.7938\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  467.4891\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  467.2922\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  467.5337\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  467.7072\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  465.8839\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  465.1910\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  465.4494\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  463.2359\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  462.1937\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  472.1243\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  491.1006\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  553.0349\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], \n",
       "  598.3411\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)]]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {\n",
    "    'epoch': epoch,\n",
    "    'lstmLayer': lstmLayer.state_dict(),\n",
    "    'predictLayer': predictLayer.state_dict(),\n",
    "    'lstm_optimizer': lstmOptimizer.state_dict(),\n",
    "    'predict_optimizer': predictOptimizer.state_dict()\n",
    "}\n",
    "ckpt_path = 'data\\ckpt\\basic_most\\model.pt'\n",
    "# torch.save(state_dict, '/data/ckpt/basic_most/model.pt')\n",
    "torch.save(state_dict, 'basic_most_model_working_epoch_200_lr_01_hidden_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainPredictions = []\n",
    "log_probs = []\n",
    "h = None\n",
    "c = None\n",
    "for (i, headlines) in enumerate(basictrain):\n",
    "        log_prob, h, c = lstmLayer(headlines, h, c)\n",
    "        log_probs.append(log_prob)\n",
    "        if float(log_prob[0][0]) > float(log_prob[0][1]):\n",
    "            trainPredictions.append(0)\n",
    "        else:\n",
    "            trainPredictions.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 232, 1: 268})"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(trainPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testPredictions = []\n",
    "log_probs = []\n",
    "# h = hidden\n",
    "# c = cell\n",
    "for (i, headlines) in enumerate(basictest):\n",
    "        log_prob, h, c = lstmLayer(headlines, h, c)\n",
    "        log_probs.append(log_prob)\n",
    "        if float(log_prob[0][0]) > float(log_prob[0][1]):\n",
    "            testPredictions.append(0)\n",
    "        else:\n",
    "            testPredictions.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.998137802607\n",
      "[[737   1]\n",
      " [  2 871]]\n",
      "Test Accuracy: 0.452380952381\n",
      "[[ 72 114]\n",
      " [ 93  99]]\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', sum(np.asarray(trainPredictions) == np.asarray(trainLabels))/len(trainLabels))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(trainLabels, trainPredictions))\n",
    "\n",
    "print('Test Accuracy:', sum(np.asarray(testPredictions) == np.asarray(testLabels))/len(testLabels))\n",
    "print(confusion_matrix(testLabels, testPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 6 \n",
       "    404.1833     1.0000 -1493.9633  -476.9284  -382.5286     0.0000   437.7519\n",
       "\n",
       "Columns 7 to 13 \n",
       "   1359.5787    -0.0064     0.0000    -2.9580     1.0000     0.0000    56.6718\n",
       "\n",
       "Columns 14 to 20 \n",
       "     -0.0000   578.1794     1.0000    -0.0000    -0.0000     2.9995     0.5660\n",
       "\n",
       "Columns 21 to 27 \n",
       "      9.0044    -1.0000   -12.5238     0.0000    -1.0000     0.0000     1.9999\n",
       "\n",
       "Columns 28 to 29 \n",
       "     -0.0000     0.0000\n",
       "[torch.cuda.FloatTensor of size 1x1x30 (GPU 0)]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-cpu]",
   "language": "python",
   "name": "conda-env-tf-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
